{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_tagging_Spacy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **POS tagging and Symptom Extraction using Spacy**"
      ],
      "metadata": {
        "id": "VWjX53zbjmYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As NLTK was inconsistent, we used Spacy for the purpose of POS Tagging and hence doing symptom extraction by converting the text into unigram and bigram, and extracting the favourably tagged data.\n",
        "\n"
      ],
      "metadata": {
        "id": "XZGggwyNj5JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1:\n",
        "\n",
        "* Extracting General Symptoms using POS tagging and extracting relevant POS's"
      ],
      "metadata": {
        "id": "fZc7WcvHlFSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dZt2HKCjSCu"
      },
      "outputs": [],
      "source": [
        "def general_symptom_extaction(text):  \n",
        "  symptoms=[]\n",
        "  doc = nlp(text)\n",
        "  \n",
        "  bigram=[]\n",
        "  token=[]\n",
        "\n",
        "  for to in doc:\n",
        "    token.append((to.pos_,to.text));\n",
        "\n",
        "  for i in range(1,len(doc)):\n",
        "    bigram.append([(doc[i-1].pos_,doc[i-1].text),(doc[i].pos_,doc[i].text)])\n",
        "\n",
        "  for symp in bigram:\n",
        "    temp=\"\"\n",
        "    if(symp[0][0]==\"NOUN\" and symp[1][0]==\"NOUN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"ADJ\" and symp[1][0]==\"NOUN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"ADJ\" and symp[1][0]==\"PROPN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"PROPN\" and symp[1][0]==\"PROPN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"VERB\" and symp[1][0]==\"PROPN\"):      \n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"VERB\" and symp[1][0]==\"NOUN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"PROPN\" and symp[1][0]==\"NOUN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]\n",
        "    elif(symp[0][0]==\"NOUN\" and symp[1][0]==\"PROPN\"):\n",
        "      temp+=symp[0][1]+\" \"+symp[1][1]  \n",
        "\n",
        "    if(len(temp)>0):\n",
        "      symptoms.append(temp)    \n",
        "\n",
        "  for symp in token:\n",
        "    if(symp[0]==\"NOUN\" or symp[0]==\"PROPN\"):\n",
        "      flag=True\n",
        "      for selected in symptoms:\n",
        "        if(symp[1] in selected):\n",
        "          flag=False\n",
        "          break\n",
        "      if(flag):\n",
        "        symptoms.append(symp[1])\n",
        "\n",
        "  return symptoms                 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2:\n",
        "\n",
        "* Getting specific symptoms by using a bot like yes/no approach."
      ],
      "metadata": {
        "id": "FtcIPxKFmDSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def specific_symptom_extraction(text):\n",
        "  i=0\n",
        "  j=0\n",
        "  while(text[i]=='' and i<len(text)):\n",
        "    i+=1\n",
        "  j=i\n",
        "  while(text[j]!='YES' and text[j]!='NO' and j<len(text)):\n",
        "    j+=1\n",
        "  \n",
        "  symptoms=[]\n",
        "  if(text[j]=='YES'):\n",
        "    temp=''\n",
        "    while(i!=j):\n",
        "      temp+=text[i]+' '\n",
        "      i+=1\n",
        "    symptoms.append(temp)  \n",
        "\n",
        "  i=j\n",
        "  j+=1\n",
        "  while(j<len(text)):\n",
        "    if(text[j]=='YES'):\n",
        "      temp=''\n",
        "      i+=1\n",
        "      while(i!=j):\n",
        "        temp+=text[i]+' '\n",
        "        i+=1\n",
        "      symptoms.append(temp)  \n",
        "    elif(text[j]=='NO'):\n",
        "      i=j    \n",
        "    j+=1  \n",
        "\n",
        "  return symptoms"
      ],
      "metadata": {
        "id": "24IqHnLNlIqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The given text is divided into 2 parts based on a trigger and sent to the particular functions for the extraction."
      ],
      "metadata": {
        "id": "uV3A4eeomgiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])\n",
        "\n",
        "text = \"\"\"I am having depression and less hunger and weakness and sometimes fever in night now answer in yes or no vommiting yes yellow eyes no\"\"\"\n",
        "\n",
        "text=text.upper()\n",
        "\n",
        "'''\n",
        "\n",
        "Points to remember\n",
        "1. Every symptom should have a delimiter, to split\n",
        "2. trigger YES OR NO\n",
        "\n",
        "'''\n",
        "\n",
        "segments = text.split(\"YES OR NO\")\n",
        "first_segment = segments[0]\n",
        "second_segment = segments[1].split(' ')\n",
        "\n",
        "print(\"General Symptom Extracted: \",general_symptom_extaction(first_segment))\n",
        "print(\"Specific Symptom Extracted: \",specific_symptom_extraction(second_segment))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS3vfluujcHZ",
        "outputId": "0dafb794-cec2-4834-e6d1-a17144f7c2b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "General Symptom Extracted:  ['LESS HUNGER', 'SOMETIMES FEVER', 'WEAKNESS', 'NIGHT']\n",
            "Specific Symptom Extracted:  ['VOMMITING ']\n"
          ]
        }
      ]
    }
  ]
}