{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_tagging_NLTK.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **POS Tagging using NLTK**"
      ],
      "metadata": {
        "id": "olc5aHJrYlYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rather than generating a summary, we moved to symptom extraction for generating an Electronic Health Report. We researched ways to extract symptoms from text and found some algorithms whilst reading [this](https://www.ijert.org/symptoms-extraction-from-a-voice-input-using-natural-language-processing).\n",
        "\n",
        "Hence we implemented POS tagging with NLTK"
      ],
      "metadata": {
        "id": "TMY5n2ToZAUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons why we didn't use this**\n",
        "\n",
        "NLTK was irregular and non consistent in the required POS tagging.\n",
        "\n",
        "For example, vommiting was tagged as VERB somewhere and NOUN somewhere."
      ],
      "metadata": {
        "id": "ey8dLo5BcGYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCfJfAeLYd-c",
        "outputId": "011774f7-5310-47f6-8ce6-df7645dedaef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am facing a severe pain in chest. Also sometimes continous sneezing is there\"\n",
        "tokenized = sent_tokenize(text)\n",
        "symptoms = []\n",
        "for i in tokenized:\n",
        "    wordsList = nltk.word_tokenize(i)\n",
        "    wordsList = [lemmatizer.lemmatize(w) for w in wordsList if not w in stop_words] \n",
        "    tagged = nltk.pos_tag(wordsList)\n",
        "  \n",
        "    print(tagged)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UHsNi3qYuHq",
        "outputId": "2085d72a-7418-4b80-b1c5-2a9b54340dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('facing', 'VBG'), ('severe', 'JJ'), ('pain', 'NN'), ('chest', 'NN'), ('.', '.')]\n",
            "[('Also', 'RB'), ('sometimes', 'RB'), ('continous', 'JJ'), ('sneezing', 'VBG')]\n"
          ]
        }
      ]
    }
  ]
}