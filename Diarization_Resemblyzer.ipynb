{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diarization_Resemblyzer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Speaker Diarization Testing Using Resemblyzer**"
      ],
      "metadata": {
        "id": "3DPj7eXMubG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the audio any useful for further processing the first thing that came to our mind was to Diarize the audio and differentiate the parts where the doctor is speaking from the parts where the patient is speaking.\n",
        "\n",
        "We used the implementation of the research paper by Google Brain - [*Speaker Diarization with LSTM*](https://arxiv.org/abs/1710.10468)\n",
        "\n",
        "Using this method we were able to get the required timestamps and speakers "
      ],
      "metadata": {
        "id": "vRbi7jQv1nkw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasons why we didn't use this**\n",
        "\n",
        "The DER (Diarization Error Rate) was higher than expected which could have led to failure of the future steps of the application."
      ],
      "metadata": {
        "id": "1KDgRaH0Ob-w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1CC79r4sNC3",
        "outputId": "d2fb23b4-b267-40a0-bd32-ac7dc5b0d1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd gdrive/MyDrive/files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whw7wHqMuHOb",
        "outputId": "0cc6c11f-fbfc-44ff-e996-3f6ca468c27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBM7OFyfu4HM",
        "outputId": "80ef18b6-776f-48d7-825e-5a120d0727f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio_clip.wav  \u001b[0m\u001b[01;34mResemblyzer\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/resemble-ai/Resemblyzer.git"
      ],
      "metadata": {
        "id": "Pcr36CD6vAfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install webrtcvad"
      ],
      "metadata": {
        "id": "aoe8yiyCw7-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resemblyzer"
      ],
      "metadata": {
        "id": "a091EJ14xB32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1\n",
        "\n",
        "* The preprocess_wav function internally uses a VAD to trim out the silences in the audio file and also normalizes the decibel level of audio.\n",
        "\n",
        "* The embed_utterance function of this instance takes in the processed wav file, segments it out into windows , makes MFCCs of these segments and finally creates d-vectors of these audio segments."
      ],
      "metadata": {
        "id": "A3Wk7WN4z9-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "#give the file path to your audio file\n",
        "audio_file_path = 'audio_clip.wav'\n",
        "wav_fpath = Path(audio_file_path)\n",
        "\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "encoder = VoiceEncoder(\"cpu\")\n",
        "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
        "print(cont_embeds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zGwfPwxOkB",
        "outputId": "c26418f1-e598-4fc0-ef7a-4ae8079fa116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.04 seconds.\n",
            "(4206, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install spectralcluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xX0Y3MDxfz2",
        "outputId": "75ab92bf-3b2a-443e-bfea-61c608e7dc74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectralcluster\n",
            "  Downloading spectralcluster-0.2.4-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: spectralcluster\n",
            "Successfully installed spectralcluster-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2\n",
        "\n",
        "* Next step is the clustering of our d-vectors.\n",
        "\n"
      ],
      "metadata": {
        "id": "6iNB8TsR0qF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spectralcluster import SpectralClusterer\n",
        "from spectralcluster import RefinementOptions\n",
        "\n",
        "refinement_options = RefinementOptions(\n",
        "    gaussian_blur_sigma=1,\n",
        "    p_percentile=0.95,\n",
        "    thresholding_soft_multiplier=0.01)\n",
        "\n",
        "clusterer = SpectralClusterer(min_clusters=2,max_clusters=100,refinement_options=refinement_options)\n",
        "\n",
        "labels = clusterer.predict(cont_embeds)"
      ],
      "metadata": {
        "id": "e4QLqOifyb0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3\n",
        "\n",
        "* We need to join continuous windows which have a common speaker together."
      ],
      "metadata": {
        "id": "76-T5iqj03he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labelling(labels,wav_splits):\n",
        "    from resemblyzer.audio import sampling_rate\n",
        "    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
        "    labelling = []\n",
        "    start_time = 0\n",
        "\n",
        "    for i,time in enumerate(times):\n",
        "        if i>0 and labels[i]!=labels[i-1]:\n",
        "            temp = [str(labels[i-1]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "            start_time = time\n",
        "        if i==len(times)-1:\n",
        "            temp = [str(labels[i]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "\n",
        "    return labelling\n",
        "  \n",
        "labelling = create_labelling(labels,wav_splits)"
      ],
      "metadata": {
        "id": "JrHbq-gjyfTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Finally we get the labelling and the timestamps of the different people speaking "
      ],
      "metadata": {
        "id": "a5Mr14bH062-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(labelling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QIjuqFdy9-e",
        "outputId": "54ef1607-80c2-40da-feea-eb135eb1c160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('0', 0, 13.7), ('1', 13.7, 20.78), ('0', 20.78, 21.14), ('1', 21.14, 24.98), ('0', 24.98, 28.4), ('1', 28.4, 28.58), ('0', 28.58, 28.76), ('1', 28.76, 32.48), ('0', 32.48, 35.42), ('1', 35.42, 36.26), ('0', 36.26, 36.38), ('1', 36.38, 47.12), ('0', 47.12, 47.72), ('1', 47.72, 47.78), ('0', 47.78, 50.06), ('1', 50.06, 50.66), ('0', 50.66, 50.72), ('1', 50.72, 60.86), ('0', 60.86, 68.3), ('1', 68.3, 91.34), ('0', 91.34, 91.58), ('1', 91.58, 91.7), ('0', 91.7, 91.76), ('1', 91.76, 92.3), ('0', 92.3, 92.6), ('1', 92.6, 106.22), ('0', 106.22, 111.86), ('1', 111.86, 121.16), ('0', 121.16, 121.28), ('1', 121.28, 121.46), ('0', 121.46, 121.52), ('1', 121.52, 130.22), ('0', 130.22, 130.34), ('1', 130.34, 132.2), ('0', 132.2, 132.26), ('1', 132.26, 154.94), ('0', 154.94, 155.3), ('1', 155.3, 161.06), ('0', 161.06, 165.56), ('1', 165.56, 179.12), ('0', 179.12, 179.18), ('1', 179.18, 184.16), ('0', 184.16, 184.34), ('1', 184.34, 190.52), ('0', 190.52, 190.58), ('1', 190.58, 190.64), ('0', 190.64, 191.6), ('1', 191.6, 203.18), ('0', 203.18, 203.24), ('1', 203.24, 208.88), ('0', 208.88, 209.06), ('1', 209.06, 209.48), ('0', 209.48, 209.54), ('1', 209.54, 220.88), ('0', 220.88, 253.1)]\n"
          ]
        }
      ]
    }
  ]
}